{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的線性迴歸模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "試著使用 sklearn datasets 的其他資料集 (wine, boston, ...)，來訓練自己的線性迴歸模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HINT: 注意 label 的型態，確定資料集的目標是分類還是回歸，在使用正確的模型訓練！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#分類問題 用logistic regression\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, random_state=4)\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 17.04\n"
     ]
    }
   ],
   "source": [
    "#回歸問題 用Linear regression\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.1, random_state=4)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-1.25856659e-01  4.84257396e-02  1.84085281e-02  3.08509569e+00\n",
      " -1.73277018e+01  3.61674713e+00  2.19181853e-03 -1.49361132e+00\n",
      "  3.19979200e-01 -1.27294649e-02 -9.27469086e-01  9.50912468e-03\n",
      " -5.33592471e-01]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.575],\n",
       "       [6.421],\n",
       "       [7.185],\n",
       "       [6.998],\n",
       "       [7.147],\n",
       "       [6.43 ],\n",
       "       [6.012],\n",
       "       [6.172],\n",
       "       [5.631],\n",
       "       [6.004],\n",
       "       [6.377],\n",
       "       [6.009],\n",
       "       [5.889],\n",
       "       [5.949],\n",
       "       [6.096],\n",
       "       [5.834],\n",
       "       [5.935],\n",
       "       [5.99 ],\n",
       "       [5.456],\n",
       "       [5.727],\n",
       "       [5.57 ],\n",
       "       [5.965],\n",
       "       [6.142],\n",
       "       [5.813],\n",
       "       [5.924],\n",
       "       [5.599],\n",
       "       [5.813],\n",
       "       [6.047],\n",
       "       [6.495],\n",
       "       [6.674],\n",
       "       [5.713],\n",
       "       [6.072],\n",
       "       [5.95 ],\n",
       "       [5.701],\n",
       "       [6.096],\n",
       "       [5.933],\n",
       "       [5.841],\n",
       "       [5.85 ],\n",
       "       [5.966],\n",
       "       [6.595],\n",
       "       [7.024],\n",
       "       [6.77 ],\n",
       "       [6.169],\n",
       "       [6.211],\n",
       "       [6.069],\n",
       "       [5.682],\n",
       "       [5.786],\n",
       "       [6.03 ],\n",
       "       [5.399],\n",
       "       [5.602],\n",
       "       [5.963],\n",
       "       [6.115],\n",
       "       [6.511],\n",
       "       [5.998],\n",
       "       [5.888],\n",
       "       [7.249],\n",
       "       [6.383],\n",
       "       [6.816],\n",
       "       [6.145],\n",
       "       [5.927],\n",
       "       [5.741],\n",
       "       [5.966],\n",
       "       [6.456],\n",
       "       [6.762],\n",
       "       [7.104],\n",
       "       [6.29 ],\n",
       "       [5.787],\n",
       "       [5.878],\n",
       "       [5.594],\n",
       "       [5.885],\n",
       "       [6.417],\n",
       "       [5.961],\n",
       "       [6.065],\n",
       "       [6.245],\n",
       "       [6.273],\n",
       "       [6.286],\n",
       "       [6.279],\n",
       "       [6.14 ],\n",
       "       [6.232],\n",
       "       [5.874],\n",
       "       [6.727],\n",
       "       [6.619],\n",
       "       [6.302],\n",
       "       [6.167],\n",
       "       [6.389],\n",
       "       [6.63 ],\n",
       "       [6.015],\n",
       "       [6.121],\n",
       "       [7.007],\n",
       "       [7.079],\n",
       "       [6.417],\n",
       "       [6.405],\n",
       "       [6.442],\n",
       "       [6.211],\n",
       "       [6.249],\n",
       "       [6.625],\n",
       "       [6.163],\n",
       "       [8.069],\n",
       "       [7.82 ],\n",
       "       [7.416],\n",
       "       [6.727],\n",
       "       [6.781],\n",
       "       [6.405],\n",
       "       [6.137],\n",
       "       [6.167],\n",
       "       [5.851],\n",
       "       [5.836],\n",
       "       [6.127],\n",
       "       [6.474],\n",
       "       [6.229],\n",
       "       [6.195],\n",
       "       [6.715],\n",
       "       [5.913],\n",
       "       [6.092],\n",
       "       [6.254],\n",
       "       [5.928],\n",
       "       [6.176],\n",
       "       [6.021],\n",
       "       [5.872],\n",
       "       [5.731],\n",
       "       [5.87 ],\n",
       "       [6.004],\n",
       "       [5.961],\n",
       "       [5.856],\n",
       "       [5.879],\n",
       "       [5.986],\n",
       "       [5.613],\n",
       "       [5.693],\n",
       "       [6.431],\n",
       "       [5.637],\n",
       "       [6.458],\n",
       "       [6.326],\n",
       "       [6.372],\n",
       "       [5.822],\n",
       "       [5.757],\n",
       "       [6.335],\n",
       "       [5.942],\n",
       "       [6.454],\n",
       "       [5.857],\n",
       "       [6.151],\n",
       "       [6.174],\n",
       "       [5.019],\n",
       "       [5.403],\n",
       "       [5.468],\n",
       "       [4.903],\n",
       "       [6.13 ],\n",
       "       [5.628],\n",
       "       [4.926],\n",
       "       [5.186],\n",
       "       [5.597],\n",
       "       [6.122],\n",
       "       [5.404],\n",
       "       [5.012],\n",
       "       [5.709],\n",
       "       [6.129],\n",
       "       [6.152],\n",
       "       [5.272],\n",
       "       [6.943],\n",
       "       [6.066],\n",
       "       [6.51 ],\n",
       "       [6.25 ],\n",
       "       [7.489],\n",
       "       [7.802],\n",
       "       [8.375],\n",
       "       [5.854],\n",
       "       [6.101],\n",
       "       [7.929],\n",
       "       [5.877],\n",
       "       [6.319],\n",
       "       [6.402],\n",
       "       [5.875],\n",
       "       [5.88 ],\n",
       "       [5.572],\n",
       "       [6.416],\n",
       "       [5.859],\n",
       "       [6.546],\n",
       "       [6.02 ],\n",
       "       [6.315],\n",
       "       [6.86 ],\n",
       "       [6.98 ],\n",
       "       [7.765],\n",
       "       [6.144],\n",
       "       [7.155],\n",
       "       [6.563],\n",
       "       [5.604],\n",
       "       [6.153],\n",
       "       [7.831],\n",
       "       [6.782],\n",
       "       [6.556],\n",
       "       [7.185],\n",
       "       [6.951],\n",
       "       [6.739],\n",
       "       [7.178],\n",
       "       [6.8  ],\n",
       "       [6.604],\n",
       "       [7.875],\n",
       "       [7.287],\n",
       "       [7.107],\n",
       "       [7.274],\n",
       "       [6.975],\n",
       "       [7.135],\n",
       "       [6.162],\n",
       "       [7.61 ],\n",
       "       [7.853],\n",
       "       [8.034],\n",
       "       [5.891],\n",
       "       [6.326],\n",
       "       [5.783],\n",
       "       [6.064],\n",
       "       [5.344],\n",
       "       [5.96 ],\n",
       "       [5.404],\n",
       "       [5.807],\n",
       "       [6.375],\n",
       "       [5.412],\n",
       "       [6.182],\n",
       "       [5.888],\n",
       "       [6.642],\n",
       "       [5.951],\n",
       "       [6.373],\n",
       "       [6.951],\n",
       "       [6.164],\n",
       "       [6.879],\n",
       "       [6.618],\n",
       "       [8.266],\n",
       "       [8.725],\n",
       "       [8.04 ],\n",
       "       [7.163],\n",
       "       [7.686],\n",
       "       [6.552],\n",
       "       [5.981],\n",
       "       [7.412],\n",
       "       [8.337],\n",
       "       [8.247],\n",
       "       [6.726],\n",
       "       [6.086],\n",
       "       [6.631],\n",
       "       [7.358],\n",
       "       [6.481],\n",
       "       [6.606],\n",
       "       [6.897],\n",
       "       [6.095],\n",
       "       [6.358],\n",
       "       [6.393],\n",
       "       [5.593],\n",
       "       [5.605],\n",
       "       [6.108],\n",
       "       [6.226],\n",
       "       [6.433],\n",
       "       [6.718],\n",
       "       [6.487],\n",
       "       [6.438],\n",
       "       [6.957],\n",
       "       [8.259],\n",
       "       [6.108],\n",
       "       [5.876],\n",
       "       [7.454],\n",
       "       [8.704],\n",
       "       [7.333],\n",
       "       [6.842],\n",
       "       [7.203],\n",
       "       [7.52 ],\n",
       "       [8.398],\n",
       "       [7.327],\n",
       "       [7.206],\n",
       "       [5.56 ],\n",
       "       [7.014],\n",
       "       [8.297],\n",
       "       [7.47 ],\n",
       "       [5.92 ],\n",
       "       [5.856],\n",
       "       [6.24 ],\n",
       "       [6.538],\n",
       "       [7.691],\n",
       "       [6.758],\n",
       "       [6.854],\n",
       "       [7.267],\n",
       "       [6.826],\n",
       "       [6.482],\n",
       "       [6.812],\n",
       "       [7.82 ],\n",
       "       [6.968],\n",
       "       [7.645],\n",
       "       [7.923],\n",
       "       [7.088],\n",
       "       [6.453],\n",
       "       [6.23 ],\n",
       "       [6.209],\n",
       "       [6.315],\n",
       "       [6.565],\n",
       "       [6.861],\n",
       "       [7.148],\n",
       "       [6.63 ],\n",
       "       [6.127],\n",
       "       [6.009],\n",
       "       [6.678],\n",
       "       [6.549],\n",
       "       [5.79 ],\n",
       "       [6.345],\n",
       "       [7.041],\n",
       "       [6.871],\n",
       "       [6.59 ],\n",
       "       [6.495],\n",
       "       [6.982],\n",
       "       [7.236],\n",
       "       [6.616],\n",
       "       [7.42 ],\n",
       "       [6.849],\n",
       "       [6.635],\n",
       "       [5.972],\n",
       "       [4.973],\n",
       "       [6.122],\n",
       "       [6.023],\n",
       "       [6.266],\n",
       "       [6.567],\n",
       "       [5.705],\n",
       "       [5.914],\n",
       "       [5.782],\n",
       "       [6.382],\n",
       "       [6.113],\n",
       "       [6.426],\n",
       "       [6.376],\n",
       "       [6.041],\n",
       "       [5.708],\n",
       "       [6.415],\n",
       "       [6.431],\n",
       "       [6.312],\n",
       "       [6.083],\n",
       "       [5.868],\n",
       "       [6.333],\n",
       "       [6.144],\n",
       "       [5.706],\n",
       "       [6.031],\n",
       "       [6.316],\n",
       "       [6.31 ],\n",
       "       [6.037],\n",
       "       [5.869],\n",
       "       [5.895],\n",
       "       [6.059],\n",
       "       [5.985],\n",
       "       [5.968],\n",
       "       [7.241],\n",
       "       [6.54 ],\n",
       "       [6.696],\n",
       "       [6.874],\n",
       "       [6.014],\n",
       "       [5.898],\n",
       "       [6.516],\n",
       "       [6.635],\n",
       "       [6.939],\n",
       "       [6.49 ],\n",
       "       [6.579],\n",
       "       [5.884],\n",
       "       [6.728],\n",
       "       [5.663],\n",
       "       [5.936],\n",
       "       [6.212],\n",
       "       [6.395],\n",
       "       [6.127],\n",
       "       [6.112],\n",
       "       [6.398],\n",
       "       [6.251],\n",
       "       [5.362],\n",
       "       [5.803],\n",
       "       [8.78 ],\n",
       "       [3.561],\n",
       "       [4.963],\n",
       "       [3.863],\n",
       "       [4.97 ],\n",
       "       [6.683],\n",
       "       [7.016],\n",
       "       [6.216],\n",
       "       [5.875],\n",
       "       [4.906],\n",
       "       [4.138],\n",
       "       [7.313],\n",
       "       [6.649],\n",
       "       [6.794],\n",
       "       [6.38 ],\n",
       "       [6.223],\n",
       "       [6.968],\n",
       "       [6.545],\n",
       "       [5.536],\n",
       "       [5.52 ],\n",
       "       [4.368],\n",
       "       [5.277],\n",
       "       [4.652],\n",
       "       [5.   ],\n",
       "       [4.88 ],\n",
       "       [5.39 ],\n",
       "       [5.713],\n",
       "       [6.051],\n",
       "       [5.036],\n",
       "       [6.193],\n",
       "       [5.887],\n",
       "       [6.471],\n",
       "       [6.405],\n",
       "       [5.747],\n",
       "       [5.453],\n",
       "       [5.852],\n",
       "       [5.987],\n",
       "       [6.343],\n",
       "       [6.404],\n",
       "       [5.349],\n",
       "       [5.531],\n",
       "       [5.683],\n",
       "       [4.138],\n",
       "       [5.608],\n",
       "       [5.617],\n",
       "       [6.852],\n",
       "       [5.757],\n",
       "       [6.657],\n",
       "       [4.628],\n",
       "       [5.155],\n",
       "       [4.519],\n",
       "       [6.434],\n",
       "       [6.782],\n",
       "       [5.304],\n",
       "       [5.957],\n",
       "       [6.824],\n",
       "       [6.411],\n",
       "       [6.006],\n",
       "       [5.648],\n",
       "       [6.103],\n",
       "       [5.565],\n",
       "       [5.896],\n",
       "       [5.837],\n",
       "       [6.202],\n",
       "       [6.193],\n",
       "       [6.38 ],\n",
       "       [6.348],\n",
       "       [6.833],\n",
       "       [6.425],\n",
       "       [6.436],\n",
       "       [6.208],\n",
       "       [6.629],\n",
       "       [6.461],\n",
       "       [6.152],\n",
       "       [5.935],\n",
       "       [5.627],\n",
       "       [5.818],\n",
       "       [6.406],\n",
       "       [6.219],\n",
       "       [6.485],\n",
       "       [5.854],\n",
       "       [6.459],\n",
       "       [6.341],\n",
       "       [6.251],\n",
       "       [6.185],\n",
       "       [6.417],\n",
       "       [6.749],\n",
       "       [6.655],\n",
       "       [6.297],\n",
       "       [7.393],\n",
       "       [6.728],\n",
       "       [6.525],\n",
       "       [5.976],\n",
       "       [5.936],\n",
       "       [6.301],\n",
       "       [6.081],\n",
       "       [6.701],\n",
       "       [6.376],\n",
       "       [6.317],\n",
       "       [6.513],\n",
       "       [6.209],\n",
       "       [5.759],\n",
       "       [5.952],\n",
       "       [6.003],\n",
       "       [5.926],\n",
       "       [5.713],\n",
       "       [6.167],\n",
       "       [6.229],\n",
       "       [6.437],\n",
       "       [6.98 ],\n",
       "       [5.427],\n",
       "       [6.162],\n",
       "       [6.484],\n",
       "       [5.304],\n",
       "       [6.185],\n",
       "       [6.229],\n",
       "       [6.242],\n",
       "       [6.75 ],\n",
       "       [7.061],\n",
       "       [5.762],\n",
       "       [5.871],\n",
       "       [6.312],\n",
       "       [6.114],\n",
       "       [5.905],\n",
       "       [5.454],\n",
       "       [5.414],\n",
       "       [5.093],\n",
       "       [5.983],\n",
       "       [5.983],\n",
       "       [5.707],\n",
       "       [5.926],\n",
       "       [5.67 ],\n",
       "       [5.39 ],\n",
       "       [5.794],\n",
       "       [6.019],\n",
       "       [5.569],\n",
       "       [6.027],\n",
       "       [6.593],\n",
       "       [6.12 ],\n",
       "       [6.976],\n",
       "       [6.794],\n",
       "       [6.03 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#嘗試只取一項特徵\n",
    "X = boston.data[:, np.newaxis, 5]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, boston.target, test_size=0.1, random_state=4)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_test, y_test,  color='black')\n",
    "plt.plot(x_test, y_pred, color='blue', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 32.40\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
